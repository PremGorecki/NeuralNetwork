{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_classification_metrics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPC+CqFRuC4gVYe0gddAem3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PremGorecki/NeuralNetwork/blob/main/02_basics/04_classification_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import bibliotek"
      ],
      "metadata": {
        "id": "bYmrCeZZI3Ck"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N5KkOIxxIBQ7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Metryki - Klasyfikacja binarna\n",
        "\n",
        "2.1 Accuracy - Dokładność klasyfikacji"
      ],
      "metadata": {
        "id": "_2DbsOrKJDXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array([1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1])\n",
        "y_pred = np.array([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ],
      "metadata": {
        "id": "5jeR1zhIJGCx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    correct = 0\n",
        "    for idx, _ in enumerate(y_true):\n",
        "        if y_true[idx] == y_pred[idx]:\n",
        "            correct += 1\n",
        "    return correct / len(y_true) * 100"
      ],
      "metadata": {
        "id": "ASCtxNnLJJOi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(y_true, y_pred)"
      ],
      "metadata": {
        "id": "D2c6rzBDJRyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
        "results = results.sort_values(by='y_true')\n",
        "results['sample'] = range(1, len(y_true) + 1)\n",
        "results"
      ],
      "metadata": {
        "id": "fN0Hx-9jJ4fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(rows=2, cols=1)\n",
        "fig.add_trace(go.Scatter(x=results['sample'], y=results['y_true'], mode='markers', name='y_true'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=results['sample'], y=results['y_pred'], mode='markers', name='y_pred'), row=2, col=1)\n",
        "fig.update_layout(width=1000, height=800, title='Binary classifier predictions')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "50Tpt4laKcp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Macierz konfuzji/pomyłek"
      ],
      "metadata": {
        "id": "c5D1BWgDLPyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importujemy ją ze sklear\n",
        "# u nas macierz 2 x 2 bo klasyfikacja binarna to 2 możliwe wyniki\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "-tpFhtoLLQfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.figure_factory as ff\n",
        "\n",
        "def plot_confusion_matrix(cm):\n",
        "    cm = cm[::-1]\n",
        "    cm = pd.DataFrame(cm, columns=['pred_0', 'pred_1'], index=['true_1', 'true_0'])\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(z=cm.values, x=list(cm.columns), y=list(cm.index), colorscale='ice', showscale=True, reversescale=True)\n",
        "    fig.update_layout(width=500, height=500, title='Confusion Matrix', font_size=16)\n",
        "    fig.show()\n",
        "\n",
        "plot_confusion_matrix(cm)"
      ],
      "metadata": {
        "id": "BG_Hni9xLsMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# możemy sobie też wrzucić to do obiektu DataFrame\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm_df = pd.DataFrame(cm, columns=['pred_0', 'pred_1'], index=['true_0', 'true_1'])\n",
        "cm_df"
      ],
      "metadata": {
        "id": "SpMhoeSWL3QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(f'TN - True Negative: {tn}')\n",
        "print(f'FP - False Positive: {fp}')\n",
        "print(f'FN - False Negative: {fn}')\n",
        "print(f'TP - True Positive: {tp}')"
      ],
      "metadata": {
        "id": "ETKNX67DM0kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Rate - Type I error\n",
        "fpr = fp / (fp + tn)\n",
        "print(fpr)"
      ],
      "metadata": {
        "id": "4tTJrlLsM9ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# False Negative Rate - Type II error\n",
        "fnr = fn / (fn + tp)\n",
        "print(fnr)"
      ],
      "metadata": {
        "id": "Lw06N09oN98h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision - ile obserwacji przewidywanych jako pozytywne są w rzeczywistości pozytywne\n",
        "precision = tp / (tp + fp)\n",
        "print(precision)"
      ],
      "metadata": {
        "id": "K4rrkulROW3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recall - jak wiele obserwacji z wzystkich poytywnych sklasyfikowaliśmy jako pozytywne\n",
        "recall = tp / (tp + fn)\n",
        "print(recall)"
      ],
      "metadata": {
        "id": "wND13-HkOeU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3 Krzywa ROC (ROK)"
      ],
      "metadata": {
        "id": "lcO8hwbdWcUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Krzywa ROC\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, tresh = roc_curve(y_true, y_pred, pos_label=1)"
      ],
      "metadata": {
        "id": "pAlRZ3ozSkCU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc = pd.DataFrame({'fpr': fpr, 'tpr': tpr})\n",
        "roc"
      ],
      "metadata": {
        "id": "JPeNMGGsSlUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(y_true, y_pred):\n",
        "    # Binary classification\n",
        "    from sklearn.metrics import roc_curve\n",
        "    fpr, tpr, tresh = roc_curve(y_true, y_pred, pos_label=1)\n",
        "\n",
        "    fig = go.Figure(data=[go.Scatter(x=roc['fpr'], y=roc['tpr'], line_color='red', name='ROC Curve'),\n",
        "                        go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line_dash='dash', line_color='navy')],\n",
        "                    layout=go.Layout(xaxis_title='False Positive Rate',\n",
        "                                    yaxis_title='True Positive Rate',\n",
        "                                    title='ROC Curve',\n",
        "                                    showlegend=False,\n",
        "                                    width=800))\n",
        "    fig.show()\n",
        "plot_roc_curve(y_true, y_pred)"
      ],
      "metadata": {
        "id": "0G-npQ3cTVWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUC Score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc = roc_auc_score(y_true, y_pred)\n",
        "roc_auc"
      ],
      "metadata": {
        "id": "GUiKCcgtT-Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Metryki - Klasyfikacja wieloklasowa\n",
        "\n",
        "3.1 Accuracy - Dokładność klasyfikacji"
      ],
      "metadata": {
        "id": "LWdKmS7EUTnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array([1, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 2, 1, 1, 2, 2])\n",
        "y_pred = np.array([0, 0, 1, 2, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 2, 1, 2, 1, 2])\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "ef3nVzMhUUoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Macierz konfuzji/pomyłek"
      ],
      "metadata": {
        "id": "VZXqs5JFVEyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "CGCRTN6rVG83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm):\n",
        "    cm = cm[::-1]\n",
        "    cm = pd.DataFrame(cm, columns=['pred_0', 'pred_1', 'pred_2'], index=['true_2','true_1', 'true_0'])\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(z=cm.values, x=list(cm.columns), y=list(cm.index), colorscale='ice', showscale=True, reversescale=True)\n",
        "    fig.update_layout(width=500, height=500, title='Confusion Matrix', font_size=16)\n",
        "    fig.show()\n",
        "\n",
        "plot_confusion_matrix(cm)"
      ],
      "metadata": {
        "id": "RbCqbH1EVKUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3 Raport klasyfikacji"
      ],
      "metadata": {
        "id": "ON8HgHwNVxGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "stkxcGETVym6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}